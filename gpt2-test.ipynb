{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # 一个完整GPT2训练流程"]},{"cell_type":"markdown","metadata":{},"source":["## 定义tokenizer和文本处理"]},{"cell_type":"markdown","metadata":{},"source":[">  没办法，使用autodl启用学术加速，不需要的不执行就好\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import subprocess\n","import os\n","\n","result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n","output = result.stdout\n","for line in output.splitlines():\n","    if '=' in line:\n","        var, value = line.split('=', 1)\n","        os.environ[var] = value"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-09-15T09:48:02.028409Z","iopub.status.busy":"2023-09-15T09:48:02.027664Z","iopub.status.idle":"2023-09-15T09:48:02.216998Z","shell.execute_reply":"2023-09-15T09:48:02.216042Z","shell.execute_reply.started":"2023-09-15T09:48:02.028375Z"},"trusted":true},"outputs":[],"source":["from transformers import GPT2Tokenizer\n","#\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","tokenizer.pad_token = tokenizer.eos_token\n","def preprocess(text):\n","    encoding = tokenizer.encode_plus(text,max_length=512 ,truncation=True, padding='max_length', return_tensors='pt')\n","    input_ids = encoding['input_ids']\n","    attention_mask = encoding['attention_mask']\n","    return input_ids, attention_mask\n"]},{"cell_type":"markdown","metadata":{},"source":["### 测试显卡命令"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-15T09:48:06.409802Z","iopub.status.busy":"2023-09-15T09:48:06.409424Z","iopub.status.idle":"2023-09-15T09:48:07.405303Z","shell.execute_reply":"2023-09-15T09:48:07.404145Z","shell.execute_reply.started":"2023-09-15T09:48:06.409771Z"},"trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-08-24T10:01:46.284186Z","iopub.status.busy":"2023-08-24T10:01:46.283107Z","iopub.status.idle":"2023-08-24T10:01:47.299725Z","shell.execute_reply":"2023-08-24T10:01:47.298522Z","shell.execute_reply.started":"2023-08-24T10:01:46.284145Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Mon_Oct_12_20:09:46_PDT_2020\n","Cuda compilation tools, release 11.1, V11.1.105\n","Build cuda_11.1.TC455_06.29190527_0\n"]}],"source":["!nvcc -V"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-09-15T09:48:21.920261Z","iopub.status.busy":"2023-09-15T09:48:21.919872Z","iopub.status.idle":"2023-09-15T09:48:23.220857Z","shell.execute_reply":"2023-09-15T09:48:23.219695Z","shell.execute_reply.started":"2023-09-15T09:48:21.920228Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m\u001b[37mautodl-container-28ce11b552-1f3ab94c\u001b[m  Fri Sep 15 18:00:01 2023  \u001b[1m\u001b[30m525.89.02\u001b[m\n","\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce RTX 2080 Ti\u001b[m |\u001b[31m 31°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m11264\u001b[m MB |\n"]}],"source":["!gpustat -c -p -u"]},{"cell_type":"markdown","metadata":{},"source":["# train函数的定义"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-09-15T09:48:26.590994Z","iopub.status.busy":"2023-09-15T09:48:26.590579Z","iopub.status.idle":"2023-09-15T09:48:29.654578Z","shell.execute_reply":"2023-09-15T09:48:29.653599Z","shell.execute_reply.started":"2023-09-15T09:48:26.590960Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["finish\n"]}],"source":["#train函数的定义\n","import torch\n","\n","def train(model, optimizer, epochs, training_loader):\n","    model.to(device)\n","    model.train()\n","    save_path = './model/'\n","    for epoch in range(epochs):\n","        loss = 0\n","        for i, batch in enumerate(training_loader):\n","            inputs, targets = batch\n","#             print(inputs.shape,targets.shape)\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs, labels=targets)\n","            loss = outputs.loss\n","            loss.backward()\n","            optimizer.step()\n","            if (i+1) % 20== 0:\n","                print('Epoch {:2d} | Batch {:2d}/{:2d} | Loss {:.4f}'.format(epoch+1, i+1, len(training_loader), loss))\n","        torch.save(model.state_dict(), save_path + 'epoch{}.pt'.format(epoch+1))#设置保存路径\n","        # torch.save(model.state_dict(), f'checkpoint_epoch_{epoch+1}.pt')\n","print('finish')"]},{"cell_type":"markdown","metadata":{},"source":["# 加载数据集"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-09-15T09:48:35.728428Z","iopub.status.busy":"2023-09-15T09:48:35.727449Z","iopub.status.idle":"2023-09-15T09:48:35.993354Z","shell.execute_reply":"2023-09-15T09:48:35.992377Z","shell.execute_reply.started":"2023-09-15T09:48:35.728389Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["finish setting\n"]}],"source":["\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","#定义数据类\n","class NewsDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        input_ids, attention_mask = preprocess(self.data.iloc[index]['description'])\n","        input_ids = torch.tensor(input_ids).squeeze()\n","        attention_mask = torch.tensor(attention_mask).squeeze()\n","        return input_ids, attention_mask\n","\n","dataset = pd.read_csv('./bbc_news.csv')[['description']]\n","\n","training_set = NewsDataset(dataset[:5000])\n","training_loader = DataLoader(training_set, batch_size=4)\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","# device='cpu'\n","print('finish setting')"]},{"cell_type":"markdown","metadata":{},"source":["# 训练命令"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-09-15T09:48:57.726741Z","iopub.status.busy":"2023-09-15T09:48:57.725635Z","iopub.status.idle":"2023-09-15T09:49:14.244916Z","shell.execute_reply":"2023-09-15T09:49:14.243888Z","shell.execute_reply.started":"2023-09-15T09:48:57.726699Z"},"trusted":true},"outputs":[],"source":["from transformers import AdamW\n","from transformers import GPT2LMHeadModel\n","model=GPT2LMHeadModel.from_pretrained('gpt2').to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-09-15T09:49:42.095285Z","iopub.status.busy":"2023-09-15T09:49:42.094722Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/root/miniconda3/envs/mocheg/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/tmp/ipykernel_4352/2276305946.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  input_ids = torch.tensor(input_ids).squeeze()\n","/tmp/ipykernel_4352/2276305946.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_mask = torch.tensor(attention_mask).squeeze()\n"]},{"name":"stdout","output_type":"stream","text":["Epoch  1 | Batch 20/1250 | Loss 0.5551\n","Epoch  1 | Batch 40/1250 | Loss 0.4463\n","Epoch  1 | Batch 60/1250 | Loss 0.3926\n","Epoch  1 | Batch 80/1250 | Loss 0.1702\n","Epoch  1 | Batch 100/1250 | Loss 0.0983\n","Epoch  1 | Batch 120/1250 | Loss 0.0693\n","Epoch  1 | Batch 140/1250 | Loss 0.0427\n","Epoch  1 | Batch 160/1250 | Loss 0.0437\n","Epoch  1 | Batch 180/1250 | Loss 0.0237\n","Epoch  1 | Batch 200/1250 | Loss 0.0165\n","Epoch  1 | Batch 220/1250 | Loss 0.0201\n","Epoch  1 | Batch 240/1250 | Loss 0.0137\n","Epoch  1 | Batch 260/1250 | Loss 0.0098\n","Epoch  1 | Batch 280/1250 | Loss 0.0131\n","Epoch  1 | Batch 300/1250 | Loss 0.0122\n","Epoch  1 | Batch 320/1250 | Loss 0.0174\n","Epoch  1 | Batch 340/1250 | Loss 0.0090\n","Epoch  1 | Batch 360/1250 | Loss 0.0118\n","Epoch  1 | Batch 380/1250 | Loss 0.0045\n","Epoch  1 | Batch 400/1250 | Loss 0.0062\n","Epoch  1 | Batch 420/1250 | Loss 0.0029\n","Epoch  1 | Batch 440/1250 | Loss 0.0048\n","Epoch  1 | Batch 460/1250 | Loss 0.0051\n","Epoch  1 | Batch 480/1250 | Loss 0.0026\n","Epoch  1 | Batch 500/1250 | Loss 0.0088\n","Epoch  1 | Batch 520/1250 | Loss 0.0048\n","Epoch  1 | Batch 540/1250 | Loss 0.0033\n","Epoch  1 | Batch 560/1250 | Loss 0.0093\n","Epoch  1 | Batch 580/1250 | Loss 0.0008\n","Epoch  1 | Batch 600/1250 | Loss 0.0032\n","Epoch  1 | Batch 620/1250 | Loss 0.0037\n","Epoch  1 | Batch 640/1250 | Loss 0.0065\n","Epoch  1 | Batch 660/1250 | Loss 0.0047\n","Epoch  1 | Batch 680/1250 | Loss 0.0027\n","Epoch  1 | Batch 700/1250 | Loss 0.0008\n","Epoch  1 | Batch 720/1250 | Loss 0.0037\n","Epoch  1 | Batch 740/1250 | Loss 0.0064\n","Epoch  1 | Batch 760/1250 | Loss 0.0011\n","Epoch  1 | Batch 780/1250 | Loss 0.0064\n","Epoch  1 | Batch 800/1250 | Loss 0.0007\n","Epoch  1 | Batch 820/1250 | Loss 0.0067\n","Epoch  1 | Batch 840/1250 | Loss 0.0042\n","Epoch  1 | Batch 860/1250 | Loss 0.0006\n","Epoch  1 | Batch 880/1250 | Loss 0.0034\n","Epoch  1 | Batch 900/1250 | Loss 0.0003\n","Epoch  1 | Batch 920/1250 | Loss 0.0072\n","Epoch  1 | Batch 940/1250 | Loss 0.0061\n","Epoch  1 | Batch 960/1250 | Loss 0.0033\n","Epoch  1 | Batch 980/1250 | Loss 0.0034\n","Epoch  1 | Batch 1000/1250 | Loss 0.0058\n","Epoch  1 | Batch 1020/1250 | Loss 0.0036\n","Epoch  1 | Batch 1040/1250 | Loss 0.0067\n","Epoch  1 | Batch 1060/1250 | Loss 0.0004\n","Epoch  1 | Batch 1080/1250 | Loss 0.0058\n","Epoch  1 | Batch 1100/1250 | Loss 0.0031\n","Epoch  1 | Batch 1120/1250 | Loss 0.0087\n","Epoch  1 | Batch 1140/1250 | Loss 0.0008\n","Epoch  1 | Batch 1160/1250 | Loss 0.0001\n","Epoch  1 | Batch 1180/1250 | Loss 0.0002\n","Epoch  1 | Batch 1200/1250 | Loss 0.0051\n","Epoch  1 | Batch 1220/1250 | Loss 0.0009\n","Epoch  1 | Batch 1240/1250 | Loss 0.0034\n","Epoch  2 | Batch 20/1250 | Loss 0.0035\n","Epoch  2 | Batch 40/1250 | Loss 0.0003\n","Epoch  2 | Batch 60/1250 | Loss 0.0006\n","Epoch  2 | Batch 80/1250 | Loss 0.0032\n","Epoch  2 | Batch 100/1250 | Loss 0.0029\n","Epoch  2 | Batch 120/1250 | Loss 0.0058\n","Epoch  2 | Batch 140/1250 | Loss 0.0033\n","Epoch  2 | Batch 160/1250 | Loss 0.0004\n","Epoch  2 | Batch 180/1250 | Loss 0.0006\n","Epoch  2 | Batch 200/1250 | Loss 0.0024\n","Epoch  2 | Batch 220/1250 | Loss 0.0007\n","Epoch  2 | Batch 240/1250 | Loss 0.0052\n","Epoch  2 | Batch 260/1250 | Loss 0.0001\n","Epoch  2 | Batch 280/1250 | Loss 0.0007\n","Epoch  2 | Batch 300/1250 | Loss 0.0001\n","Epoch  2 | Batch 320/1250 | Loss 0.0041\n","Epoch  2 | Batch 340/1250 | Loss 0.0002\n","Epoch  2 | Batch 360/1250 | Loss 0.0021\n","Epoch  2 | Batch 380/1250 | Loss 0.0001\n","Epoch  2 | Batch 400/1250 | Loss 0.0003\n","Epoch  2 | Batch 420/1250 | Loss 0.0057\n","Epoch  2 | Batch 440/1250 | Loss 0.0001\n","Epoch  2 | Batch 460/1250 | Loss 0.0006\n","Epoch  2 | Batch 480/1250 | Loss 0.0048\n","Epoch  2 | Batch 500/1250 | Loss 0.0027\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[39m=\u001b[39mGPT2LMHeadModel\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mgpt2\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m optimizer \u001b[39m=\u001b[39m AdamW(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m train(model, optimizer, \u001b[39m2\u001b[39;49m, training_loader)\n\u001b[1;32m      6\u001b[0m model\n","Cell \u001b[0;32mIn[11], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, epochs, training_loader)\u001b[0m\n\u001b[1;32m     16\u001b[0m loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[1;32m     17\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 18\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     19\u001b[0m \u001b[39mif\u001b[39;00m (i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m20\u001b[39m\u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     20\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{:2d}\u001b[39;00m\u001b[39m | Batch \u001b[39m\u001b[39m{:2d}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{:2d}\u001b[39;00m\u001b[39m | Loss \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(training_loader), loss))\n","File \u001b[0;32m~/miniconda3/envs/mocheg/lib/python3.8/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/mocheg/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniconda3/envs/mocheg/lib/python3.8/site-packages/transformers/optimization.py:466\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    462\u001b[0m state[\u001b[39m\"\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    464\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[39m# In-place operations to update the averages at the same time\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m exp_avg\u001b[39m.\u001b[39;49mmul_(beta1)\u001b[39m.\u001b[39;49madd_(grad, alpha\u001b[39m=\u001b[39;49m(\u001b[39m1.0\u001b[39;49m \u001b[39m-\u001b[39;49m beta1))\n\u001b[1;32m    467\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad, value\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[1;32m    468\u001b[0m denom \u001b[39m=\u001b[39m exp_avg_sq\u001b[39m.\u001b[39msqrt()\u001b[39m.\u001b[39madd_(group[\u001b[39m\"\u001b[39m\u001b[39meps\u001b[39m\u001b[39m\"\u001b[39m])\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from transformers import AdamW\n","from transformers import GPT2LMHeadModel\n","model=GPT2LMHeadModel.from_pretrained('gpt2').to(device)\n","optimizer = AdamW(model.parameters(), lr=1e-5)\n","train(model, optimizer, 2, training_loader)\n","model"]},{"cell_type":"markdown","metadata":{},"source":["# 测试脚本"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:59:57.163088Z","iopub.status.idle":"2023-08-24T09:59:57.165476Z","shell.execute_reply":"2023-08-24T09:59:57.165248Z","shell.execute_reply.started":"2023-08-24T09:59:57.165207Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["tensor([40954,   220], device='cuda:0')\n","trump!!!\";!!!!\";\";\";\";\"\"\";\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n"]}],"source":["text_input=torch.tensor(tokenizer.encode(\"trump \", add_special_tokens=True))\n","text_input=text_input.to(device)\n","generated = model.generate(\n","    input_ids = text_input.unsqueeze(0),\n","    max_length = 50,\n","    temperature = 1.0,\n","    top_k = 0,\n","    top_p = 0.9,\n","    do_sample=True,\n","    num_return_sequences=1\n",")\n","print(text_input)\n","generated_title = tokenizer.decode(generated[0], skip_special_tokens=True)\n","print(generated_title)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-08-24T10:00:10.812385Z","iopub.status.busy":"2023-08-24T10:00:10.812001Z","iopub.status.idle":"2023-08-24T10:00:14.686855Z","shell.execute_reply":"2023-08-24T10:00:14.685507Z","shell.execute_reply.started":"2023-08-24T10:00:10.812351Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["!pip list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!nvidia-smi\n"]},{"cell_type":"markdown","metadata":{},"source":["## 对原生的gpt2进行测试"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["tensor([40954,   318,  1893,   286,  1578,  1829,    11,   220,   220],\n","       device='cuda:0')\n","trump is president of United States,         ------------ Reply--\n","\n","Thread\n","\n","\n","Link\n","\n","He chose to defend Donald Trump over a \"stupid y'all.\"\n","\n","\n","What a y'all.\n"]}],"source":["import torch\n","from transformers import GPT2LMHeadModel, GPT2Config\n","from transformers import GPT2Tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","tokenizer.pad_token = tokenizer.eos_token\n","config = GPT2Config.from_pretrained('gpt2')\n","# model = GPT2LMHeadModel(config)\n","# model_path = './checkpoint_epoch_1.pt'\n","# model_state_dict = torch.load(model_path)\n","# model.load_state_dict(model_state_dict)\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","model.to(device)\n","text_input=torch.tensor(tokenizer.encode(\"trump is president of United States,  \", add_special_tokens=True))\n","text_input=text_input.to(device)\n","generated = model.generate(\n","    input_ids = text_input.unsqueeze(0),\n","    max_length = 50,\n","    temperature = 1.0,\n","    top_k = 0,\n","    top_p = 0.9,\n","    do_sample=True,\n","    num_return_sequences=1\n",")\n","print(text_input)\n","generated_title = tokenizer.decode(generated[0], skip_special_tokens=True)\n","print(generated_title)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 ('mocheg')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"03f970f2fc70ad2991547d92791329e0fca13cecba775a86882a30bf3ee0fa43"}}},"nbformat":4,"nbformat_minor":4}
